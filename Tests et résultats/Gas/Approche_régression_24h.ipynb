{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from holidays_es import Province\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:root@localhost:5432/euproject_dhw_data')\n",
    "df=pd.read_sql_query('SELECT datetime_per_day, g1, g2, g3,ef1,gdc,gde,tmaxd,tmedia,tmind,h1,hmedia,r1  FROM data_per_1h JOIN data_per_24h ON data_per_1h.datetime_per_hour= data_per_24h.datetime_per_day',\n",
    "    con=engine, parse_dates=['datetime_per_day'], index_col='datetime_per_day')\n",
    "\n",
    "df[['g1', 'g2', 'g3']]= df[['g1', 'g2', 'g3']]*1.02264*40/ 3.6 /1000  #from m3 to Mwh\n",
    "\n",
    "\n",
    "df[['g1','g2','g3']]=df[['g1','g2','g3']].diff()\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.gca().set(title='Consommation de la chaudiére N°01 en gaz.', xlabel='Date', ylabel='Consommation (MWh)')\n",
    "plt.plot(df.index, df['g1']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.gca().set(title='Consommation de la chaudiére N°02 en gaz.', xlabel='Date', ylabel='Consommation (Mwh)')\n",
    "plt.plot(df.index, df['g2']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.gca().set(title='Consommation de la chaudiére N°03 en gaz.', xlabel='Date', ylabel='Consommation (m3)')\n",
    "plt.plot(df.index, df['g3']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.gca().set(title='Consommation d\\'électricité', xlabel='Date', ylabel='Consommation (kwh)')\n",
    "plt.plot(df.index, df['ef1']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Détecter les valeurs négatives  => y a pas \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Détécter les données abberantes  => en utilisant le score IQR  > 28/3308 = 0.846 valeurs abberantes  \n",
    "#sns.boxplot(df['g1'])\n",
    "\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "\n",
    "df_outliers= ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))\n",
    "print(df_outliers['g1'].value_counts())\n",
    "print(df_outliers['g2'].value_counts())\n",
    "print(df_outliers['g3'].value_counts())\n",
    "print(df_outliers['ef1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Données manquntes > y a pas \n",
    "\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajout des attributs supplémentaires  : Mois, type du jour, jour férié\n",
    "\n",
    "def add_extra_attributes(df): \n",
    "    holidays= []\n",
    "    holidays.append(Province(name=\"malaga\",year=2018).holidays().get('local_holidays'))\n",
    "    holidays.append(Province(name=\"malaga\",year=2018).holidays().get('national_holidays'))\n",
    "    holidays.append(Province(name=\"malaga\",year=2018).holidays().get('regional_holidays'))\n",
    "\n",
    "    holidays.append(Province(name=\"malaga\",year=2019).holidays().get('local_holidays'))\n",
    "    holidays.append(Province(name=\"malaga\",year=2019).holidays().get('national_holidays'))\n",
    "    holidays.append(Province(name=\"malaga\",year=2019).holidays().get('regional_holidays'))\n",
    "\n",
    "    holidays.append(Province(name=\"malaga\",year=2020).holidays().get('local_holidays'))\n",
    "    holidays.append(Province(name=\"malaga\",year=2020).holidays().get('national_holidays'))\n",
    "    holidays.append(Province(name=\"malaga\",year=2020).holidays().get('regional_holidays'))\n",
    "\n",
    "    holidays.append(Province(name=\"malaga\",year=2021).holidays().get('local_holidays'))\n",
    "    holidays.append(Province(name=\"malaga\",year=2021).holidays().get('national_holidays'))\n",
    "    holidays.append(Province(name=\"malaga\",year=2021).holidays().get('regional_holidays'))\n",
    "    \n",
    "    holidays_dates=[]\n",
    "    for i in range (len(holidays)):\n",
    "        for j in range (len(holidays[i])):\n",
    "            holidays_dates.append(holidays[i][j])\n",
    "    df_holidays=pd.DataFrame({'Holidays': holidays_dates})\n",
    "\n",
    "    df['holiday'] =0\n",
    "    df['weekday']=0\n",
    "    df['month']=0\n",
    "\n",
    "    for i in range (len(df.index)):\n",
    "        if (df.index[i].weekday() == 5 or df.index[i].weekday() == 6):\n",
    "            df['weekday'][i]=1\n",
    "        df['month'][i]= df.index[i].month\n",
    "            \n",
    "        for j in range (len(df_holidays)):\n",
    "            if (df.index[i] == df_holidays['Holidays'][j]):\n",
    "                df['holiday'][i]=1\n",
    "    return df      \n",
    "\n",
    "\n",
    "df_extra=add_extra_attributes(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'g1']]\n",
    "#df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'g2']]\n",
    "#df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'g3']]\n",
    "#df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'ef1']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.values[:, :-1] #Features\n",
    "y=df.values[:, -1] #output\n",
    "\n",
    "#Normalisation\n",
    "scaler=MinMaxScaler()\n",
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(X, y)\n",
    "\n",
    "feature_names = np.array(df[['gdc', 'gde', 'h1','hmedia', 'r1' ,'tmaxd', 'tmedia', 'tmind', 'holiday', 'weekday', 'month']].columns)\n",
    "sfs_forward = SequentialFeatureSelector(reg, n_features_to_select=5, direction='forward').fit(X, y)\n",
    "print(\"Features selected by forward sequential selection: \"  f\"{feature_names[sfs_forward.get_support()]}\")\n",
    "sfs_backward = SequentialFeatureSelector(reg, n_features_to_select=5, direction='backward').fit(X, y)\n",
    "print(\"Features selected by backward sequential selection: \"  f\"{feature_names[sfs_backward.get_support()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split( X, y, test_size=0.44)\n",
    "\n",
    "reg=linear_model.LinearRegression()\n",
    "model=reg.fit(train_X, train_y)\n",
    "pred_y=model.predict(test_X)\n",
    "pred_ytrain=model.predict(train_X)\n",
    "\n",
    "print('Mean Absolute Error:', '%.4f' %  metrics.mean_absolute_error(train_y, pred_ytrain))\n",
    "print('Root Mean Squared Error:','%.4f' %  np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)))\n",
    "print('Coefficient of Variance:', '%.4f' %  ((np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean())*100))\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y, pred_y))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y, pred_y)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean())*100)\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "data = [[ metrics.mean_absolute_error(train_y, pred_ytrain),  np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)), np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean()],\n",
    "[ metrics.mean_absolute_error(test_y, pred_y),  np.sqrt(metrics.mean_squared_error(test_y, pred_y)), np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean()]]\n",
    "labels=['MAE', 'RMSE', 'CV']\n",
    "p = np.arange(len(labels))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(p - width/2, data[0], width, label='Train')\n",
    "rects2 = ax.bar(p + width/2, data[1], width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#ax.set_ylabel('Scores')\n",
    "ax.set_title('MLR sans sélction d\\'attributs')\n",
    "ax.set_xticks(p)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#exemple de validation croisé sur X et y \n",
    "\"\"\"\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "reg1 = linear_model.LinearRegression()\n",
    "reg1_errors = cross_validate(reg1, X, y, cv=10, scoring=('neg_mean_absolute_error','neg_mean_squared_error', 'neg_root_mean_squared_error', 'neg_mean_absolute_percentage_error'))\n",
    "\n",
    "print(reg1_errors['test_neg_mean_squared_error'].mean())\n",
    "print(reg1_errors['test_neg_root_mean_squared_error'].mean())\n",
    "print(reg1_errors['test_neg_mean_absolute_error'].mean())\n",
    "print((reg1_errors['test_neg_root_mean_squared_error'].mean()/y.mean())*100)\n",
    "print(reg1_errors['test_neg_mean_absolute_percentage_error'].mean())\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection d'attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features selection \n",
    "X = sfs_backward.transform(X) \n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split( X, y, test_size=0.44)\n",
    "\n",
    "reg=linear_model.LinearRegression()\n",
    "model=reg.fit(train_X, train_y)\n",
    "pred_y=model.predict(test_X)\n",
    "pred_ytrain=model.predict(train_X)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(train_y, pred_ytrain))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean())*100)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y, pred_y))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y, pred_y)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean())*100)\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "data = [[ metrics.mean_absolute_error(train_y, pred_ytrain),  np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)), np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean()],\n",
    "[ metrics.mean_absolute_error(test_y, pred_y),  np.sqrt(metrics.mean_squared_error(test_y, pred_y)), np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean()]]\n",
    "labels=['MAE', 'RMSE', 'CV']\n",
    "p = np.arange(len(labels))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(p - width/2, data[0], width, label='Train')\n",
    "rects2 = ax.bar(p + width/2, data[1], width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#ax.set_ylabel('Scores')\n",
    "ax.set_title('MLR avec sélection d\\'attributs')\n",
    "ax.set_xticks(p)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'g1']]\n",
    "#df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'g2']]\n",
    "#df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'g3']]\n",
    "#df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'ef1']]\n",
    "\n",
    "X=df.values[:, :-1] #Features\n",
    "y=df.values[:, -1] #output\n",
    "\n",
    "#Normalisation\n",
    "scaler=MinMaxScaler()\n",
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split( X, y, test_size=0.44)\n",
    "\n",
    "#Parameters Tunning\n",
    "#params = {'kernel': ('linear','poly','rbf'),'C': [0.001, 0.01, 0.1, 1, 10, 100],'gamma': [0.001, 0.01, 0.1, 1, 10, 100], 'epsilon': []}\n",
    "\n",
    "params=  {'kernel': ('linear','poly','rbf'),'C':[0.01,0.1,1,10],'gamma': [1e-7, 1e-4, 0.001, 0.1, 1],'epsilon':[0.1,0.2,0.3,0.5]}\n",
    "svr=SVR()\n",
    "\n",
    "grid_search = GridSearchCV(svr, param_grid=params ,cv=10, n_jobs=-1, verbose=0)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "#print(\"train score - \" + str(grid_search.score(train_X, train_y)))\n",
    "#print(\"test score - \" + str(grid_search.score(test_X, test_y)))\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "model=grid_search.best_estimator_\n",
    "pred_y=model.predict(test_X)\n",
    "\n",
    "pred_ytrain=model.predict(train_X)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(train_y, pred_ytrain))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean())*100)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y, pred_y))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y, pred_y)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean())*100)\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "data = [[ metrics.mean_absolute_error(train_y, pred_ytrain),  np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)), np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean()],\n",
    "[ metrics.mean_absolute_error(test_y, pred_y),  np.sqrt(metrics.mean_squared_error(test_y, pred_y)), np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean()]]\n",
    "labels=['MAE', 'RMSE', 'CV']\n",
    "p = np.arange(len(labels))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(p - width/2, data[0], width, label='Train')\n",
    "rects2 = ax.bar(p + width/2, data[1], width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#ax.set_ylabel('Scores')\n",
    "ax.set_title('SVM sans sélection d\\'attributs')\n",
    "ax.set_xticks(p)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection d'attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr=SVR()\n",
    "svr.fit(X, y)\n",
    "\n",
    "feature_names = np.array(df[['gdc', 'gde', 'h1','hmedia', 'r1' ,'tmaxd', 'tmedia', 'tmind', 'holiday', 'weekday', 'month']].columns)\n",
    "sfs_forward = SequentialFeatureSelector(svr, n_features_to_select=5, direction='forward').fit(X, y)\n",
    "print(\"Features selected by forward sequential selection: \"  f\"{feature_names[sfs_forward.get_support()]}\")\n",
    "sfs_backward = SequentialFeatureSelector(svr, n_features_to_select=5, direction='backward').fit(X, y)\n",
    "print(\"Features selected by backward sequential selection: \"  f\"{feature_names[sfs_backward.get_support()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features selection \n",
    "X = sfs_backward.transform(X) \n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split( X, y, test_size=0.44)\n",
    "\n",
    "grid_search = GridSearchCV(svr, param_grid=params ,cv=10, n_jobs=-1, verbose=0)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "model=grid_search.best_estimator_\n",
    "pred_y=model.predict(test_X)\n",
    "\n",
    "pred_ytrain=model.predict(train_X)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(train_y, pred_ytrain))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean())*100)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y, pred_y))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y, pred_y)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean())*100)\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "data = [[ metrics.mean_absolute_error(train_y, pred_ytrain),  np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)), np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean()],\n",
    "[ metrics.mean_absolute_error(test_y, pred_y),  np.sqrt(metrics.mean_squared_error(test_y, pred_y)), np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean()]]\n",
    "labels=['MAE', 'RMSE', 'CV']\n",
    "p = np.arange(len(labels))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(p - width/2, data[0], width, label='Train')\n",
    "rects2 = ax.bar(p + width/2, data[1], width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#ax.set_ylabel('Scores')\n",
    "ax.set_title('SVM avec selection d\\'attributs')\n",
    "ax.set_xticks(p)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'g1']]\n",
    "#df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'g2']]\n",
    "#df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'g3']]\n",
    "#df=df_extra[['gdc','gde',\t'tmaxd', 'tmedia','tmind','h1', 'hmedia','r1','holiday','weekday','month', 'ef1']]\n",
    "\n",
    "X=df.values[:, :-1] #Features\n",
    "y=df.values[:, -1] #output\n",
    "\n",
    "#Normalisation\n",
    "scaler=MinMaxScaler()\n",
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split( X, y, test_size=0.44)\n",
    "\n",
    "#Parameters Tunning\n",
    "params = { 'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt'], 'max_depth' : [4,5,6,7,8,10],'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "rf=RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid=params ,cv=10, n_jobs=-1, verbose=0)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "#print(\"train score - \" + str(grid_search.score(train_X, train_y)))\n",
    "#print(\"test score - \" + str(grid_search.score(test_X, test_y)))\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "model=grid_search.best_estimator_\n",
    "pred_y=model.predict(test_X)\n",
    "\n",
    "pred_ytrain=model.predict(train_X)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(train_y, pred_ytrain))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean())*100)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y, pred_y))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y, pred_y)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean())*100)\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "data = [[ metrics.mean_absolute_error(train_y, pred_ytrain),  np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)), np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean()],\n",
    "[ metrics.mean_absolute_error(test_y, pred_y),  np.sqrt(metrics.mean_squared_error(test_y, pred_y)), np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean()]]\n",
    "labels=['MAE', 'RMSE', 'CV']\n",
    "p = np.arange(len(labels))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(p - width/2, data[0], width, label='Train')\n",
    "rects2 = ax.bar(p + width/2, data[1], width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#ax.set_ylabel('Scores')\n",
    "ax.set_title('RF sans sélection d\\'attributs')\n",
    "ax.set_xticks(p)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection d'attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "feature_names = np.array(df[['gdc', 'gde', 'h1','hmedia', 'r1' ,'tmaxd', 'tmedia', 'tmind', 'holiday', 'weekday', 'month']].columns)\n",
    "sfs_forward = SequentialFeatureSelector(rf, n_features_to_select=5, direction='forward').fit(X, y)\n",
    "print(\"Features selected by forward sequential selection: \"  f\"{feature_names[sfs_forward.get_support()]}\")\n",
    "sfs_backward = SequentialFeatureSelector(rf, n_features_to_select=5, direction='backward').fit(X, y)\n",
    "print(\"Features selected by backward sequential selection: \"  f\"{feature_names[sfs_backward.get_support()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features selection \n",
    "X = sfs_backward.transform(X) \n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.44)\n",
    "rf=RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid=params ,cv=10, n_jobs=-1, verbose=0)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "model=grid_search.best_estimator_\n",
    "pred_y=model.predict(test_X)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "pred_ytrain=model.predict(train_X)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(train_y, pred_ytrain))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean())*100)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y, pred_y))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y, pred_y)))\n",
    "print('Coefficient of Variance:', (np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean())*100)\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "data = [[ metrics.mean_absolute_error(train_y, pred_ytrain),  np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain)), np.sqrt(metrics.mean_squared_error(train_y, pred_ytrain))/train_y.mean()],\n",
    "[ metrics.mean_absolute_error(test_y, pred_y),  np.sqrt(metrics.mean_squared_error(test_y, pred_y)), np.sqrt(metrics.mean_squared_error(test_y, pred_y))/test_y.mean()]]\n",
    "labels=['MAE', 'RMSE', 'CV']\n",
    "p = np.arange(len(labels))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(p - width/2, data[0], width, label='Train')\n",
    "rects2 = ax.bar(p + width/2, data[1], width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "#ax.set_ylabel('Scores')\n",
    "ax.set_title('RF avec sélection d\\'attributs')\n",
    "ax.set_xticks(p)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b998da865d9ba0601a378d306c73dd5e3dc5b65106645b358f551bbb63d2a053"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
