{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataframe from DB\n",
    "engine = create_engine('postgresql://postgres:root@localhost:5432/euproject_dhw_data')\n",
    "df=pd.read_sql_query('SELECT datetime_per_day, g1, g2, g3,ef1 FROM data_per_1h JOIN data_per_24h ON data_per_1h.datetime_per_hour= data_per_24h.datetime_per_day',\n",
    "    con=engine, parse_dates=['datetime_per_day'], index_col='datetime_per_day')\n",
    "#Conversion\n",
    "df[['g1', 'g2', 'g3']]= df[['g1', 'g2', 'g3']]*1.02264*40/ 3.6 /1000  #from m3 to MwH\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there is any missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differencing\n",
    "df[['g1','g2','g3']]=df[['g1','g2','g3']].diff()\n",
    "df.at['2021-05-18', 'g3']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.index[df['g3'] > 250]\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot G3 conumption\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.gca().set(title='Consommation de la chaudiére N°03 en gaz.', xlabel='Date', ylabel='Consommation (MWh)')\n",
    "plt.plot(df.index, df['g3']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling negative values \n",
    "a = df.index[df['g3'] < 0]\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at['2021-06-02', 'g3']=np.nan\n",
    "df.at['2021-06-15', 'g3']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Détécter les données abberantes  => en utilisant le score IQR  \n",
    "# #sns.boxplot(df['g1'])\n",
    "\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "\n",
    "df_outliers= ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))\n",
    "print(df_outliers['g1'].value_counts())\n",
    "print(df_outliers['g2'].value_counts())\n",
    "print(df_outliers['g3'].value_counts())\n",
    "print(df_outliers['ef1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values \n",
    "df=df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot G1 conumption after data cleaning\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.gca().set(title='Consommation de la chaudiére N°03 en gaz.', xlabel='Date', ylabel='Consommation (MWh)')\n",
    "plt.plot(df.index, df['g3']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM univarié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_u=df[['g3']]\n",
    "df_u=df_u.resample('M').sum()\n",
    "df_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_acf(df_u.values, lags=20)\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(df_u.values)\n",
    "    \n",
    "reframed= series_to_supervised(scaled, 2)\n",
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values = reframed_differenced.values\n",
    "values = reframed.values\n",
    "n_train_days=  int(len(values) * 0.5)\n",
    "n_val_days= int(len(values) * 0.75)\n",
    "train = values[:n_train_days, :]\n",
    "val= values[n_train_days:n_val_days, :]\n",
    "test = values[n_val_days:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "val_X, val_y = val[:, :-1], val[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "print(test_X)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "val_X= val_X.reshape((val_X.shape[0], 1,val_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "print(test_X)\n",
    "print(train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "index_test=df_u['g3'][n_val_days:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "start_time=time.time()\n",
    "history = model.fit(train_X, train_y, epochs=100, batch_size=30, validation_data=(val_X, val_y), verbose=0, shuffle=False)\n",
    "exec_time= time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='test_loss')\n",
    "plt.gca().set(title='Courbes d\\'apprentissage .', xlabel='Epochs', ylabel='Erreur')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "print(test_X.shape)\n",
    "yhat = model.predict(test_X)\n",
    "#Transform test to be 2D\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=pd.DataFrame(test_X)\n",
    "# invert scaling for forecast\n",
    "test_X[0]= yhat\n",
    "inv_yhat = scaler.inverse_transform(test_X)\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "test_X[0]= test_y\n",
    "inv_y = scaler.inverse_transform(test_X)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MAE, MSE, RMSE, CV\n",
    "MAE= metrics.mean_absolute_error(inv_y, inv_yhat)\n",
    "MSE=metrics.mean_squared_error(inv_y, inv_yhat)\n",
    "CV= (np.sqrt(metrics.mean_squared_error(inv_y, inv_yhat))/inv_y.mean())*100\n",
    "R2= metrics.r2_score(inv_y, inv_yhat)\n",
    "\n",
    "print('Mean Absolute Error:', MAE)\n",
    "print('Mean Squared Error:', MSE)  \n",
    "print('Root Mean Squared Error:', np.sqrt(MSE))\n",
    "print('Coefficient of Variance:',CV)\n",
    "print('R2:', R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(index_test[2:].index, inv_y, color='blue')\n",
    "plt.plot(index_test[2:].index, inv_yhat, color='red')\n",
    "plt.legend(('Boiler3Consumption', 'Boiler3Consumption_forcast'))\n",
    "plt.gca().set(title='Consommation de gaz de la chaudiére N°03 (month).', xlabel='Date', ylabel='Consumption (Mwh)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train on the entire dataset\n",
    "#Model serialization + Save into DB\n",
    "X, y = values[:, :-1], values[:, -1]\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "history = model.fit(X, y, epochs=100, batch_size=30, validation_data=(val_X, val_y), verbose=0, shuffle=False)\n",
    "\n",
    "model.save('C:/Users/Rayane/Desktop/saved_models/g3_month_model.h5')\n",
    "table_date= [df.index.min().date().strftime(\"%m/%d/%Y, %H:%M:%S\"), df.index.max().date().strftime(\"%m/%d/%Y, %H:%M:%S\"),]\n",
    "print(table_date)\n",
    "table_metric=[MAE, np.sqrt(MSE), CV]\n",
    "print(table_metric)\n",
    "print(type(table_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save into the database\n",
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    #Establishing the connection\n",
    "    conn = psycopg2.connect(database=\"euproject_dhw_data\", user='postgres', password='root', host='127.0.0.1', port= '5432')\n",
    "\n",
    "    #Creating a cursor object using the cursor() method\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    date = datetime.datetime.now()\n",
    "    date=date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    postgres_insert_query = \"\"\" INSERT INTO models (id_prediction, code, data_range, metrics, file) VALUES (%s,%s,%s,%s,%s)\"\"\"\n",
    "    record_to_insert = (15, 134,table_date, table_metric,\"C:/Users/Rayane/Desktop/saved_models/g3_month_model.h5\")\n",
    "    cursor.execute(postgres_insert_query, record_to_insert)\n",
    "\n",
    "    conn.commit()\n",
    "    count = cursor.rowcount\n",
    "    print(count, \"Record inserted successfully into mobile table\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Failed to insert record into mobile table\", error)\n",
    "\n",
    "finally:\n",
    "    # closing database connection.\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"PostgreSQL connection is closed\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b998da865d9ba0601a378d306c73dd5e3dc5b65106645b358f551bbb63d2a053"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
